{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alecjeffery/anaconda3/envs/spacetimeformer/lib/python3.8/site-packages/pytorch_forecasting/models/base_model.py:27: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alecjeffery/anaconda3/envs/spacetimeformer/lib/python3.8/site-packages/lightning/pytorch/utilities/parsing.py:208: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
      "/Users/alecjeffery/anaconda3/envs/spacetimeformer/lib/python3.8/site-packages/lightning/pytorch/utilities/parsing.py:208: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n",
      "/Users/alecjeffery/anaconda3/envs/spacetimeformer/lib/python3.8/site-packages/pytorch_forecasting/models/temporal_fusion_transformer/__init__.py:143: UserWarning: In pytorch-forecasting models, on versions 1.1.X, the default optimizer defaults to 'adam', if pytorch_optimizer is not installed, otherwise it defaults to 'ranger' from pytorch_optimizer. From version 1.2.0, the default optimizer will be 'adam' regardless of whether pytorch_optimizer is installed, in order to minimize the number of dependencies in default parameter settings. Users who wish to ensure their code continues using 'ranger' as optimizer should ensure that pytorch_optimizer is installed, and set the optimizer parameter explicitly to 'ranger'.\n",
      "  super().__init__(loss=loss, logging_metrics=logging_metrics, **kwargs)\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of params in network: 8501.8k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alecjeffery/anaconda3/envs/spacetimeformer/lib/python3.8/site-packages/pytorch_lightning/trainer/setup.py:187: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "/var/folders/mt/d3dxxncs4zbfjzd090b9rhph0000gn/T/ipykernel_49142/2121888546.py:189: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(modelPath, map_location=DEVICE)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TFTLightningModule(\n",
       "  (tft_model): TemporalFusionTransformer(\n",
       "    \t\"attention_head_size\":               4\n",
       "    \t\"categorical_groups\":                {}\n",
       "    \t\"causal_attention\":                  True\n",
       "    \t\"dataset_parameters\":                {'time_idx': 'time_idx', 'target': ['target_1', 'target_2'], 'group_ids': ['group'], 'weight': None, 'max_encoder_length': 90, 'min_encoder_length': 90, 'min_prediction_idx': 0, 'min_prediction_length': 5, 'max_prediction_length': 5, 'static_categoricals': ['group'], 'static_reals': [], 'time_varying_known_categoricals': [], 'time_varying_known_reals': ['time_idx'], 'time_varying_unknown_categoricals': [], 'time_varying_unknown_reals': ['open', 'high', 'low', 'target_1', 'target_2', 'vopen', 'vhigh', 'vlow', 'VIX', 'SPY', 'TNX', 'rsi14', 'rsi9', 'rsi24', 'MACD5355macddiff', 'MACD5355macddiffslope', 'MACD5355macd', 'MACD5355macdslope', 'MACD5355macdsig', 'MACD5355macdsigslope', 'MACD12269macddiff', 'MACD12269macddiffslope', 'MACD12269macd', 'MACD12269macdslope', 'MACD12269macdsig', 'MACD12269macdsigslope', 'lowTail', 'highTail', 'openTail', 'IntradayBar', 'IntradayRange', 'CloseOverSMA5', 'CloseOverSMA10', 'CloseOverSMA12', 'CloseOverSMA20', 'CloseOverSMA30', 'CloseOverSMA65', 'CloseOverSMA50', 'CloseOverSMA100', 'CloseOverSMA200', 'VolOverSMA5', 'VolOverSMA10', 'VolOverSMA12', 'VolOverSMA20', 'VolOverSMA30', 'VolOverSMA65', 'VolOverSMA50', 'VolOverSMA100', 'VolOverSMA200', 'Ret1day', 'Ret4day', 'Ret8day', 'Ret12day', 'Ret24day', 'Ret72day', 'Ret240day', 'RSC', 'bands_l', 'bands_u', 'ADX', 'cloudA', 'cloudB', 'closeVsIchA', 'closeVsIchB', 'IchAvIchB', 'CondVol_1', 'CondVol_4', 'CondVol_8', 'CondVol_12', 'CondVol_24', 'CondVol_72', 'CondVol_240', 'CV1vCV4', 'CV4vCV8', 'CV8vCV12', 'CV12vCV24', 'CV8vCV24', 'CV24vCV240', 'RSC_VIX', 'RSC_VIX_IV', 'RSC_VIX_real', 'RSC_VIX_IV_real', 'RSC_IV_gar', 'close_spy_corr22', 'close_tnx_corr22', 'vclose_VIX_corr22', 'garch_IV_corr22', 'close_spy_corr65', 'close_tnx_corr65', 'vclose_VIX_corr65', 'garch_IV_corr65', 'close_spy_corr252', 'close_tnx_corr252', 'vclose_VIX_corr252', 'garch_IV_corr252'], 'variable_groups': {}, 'constant_fill_strategy': {}, 'allow_missing_timesteps': False, 'lags': {}, 'add_relative_time_idx': False, 'add_target_scales': False, 'add_encoder_length': False, 'target_normalizer': MultiNormalizer(\n",
       "    \t\tnormalizers=[TorchNormalizer(method='identity', center=True, transformation=None, method_kwargs={}), TorchNormalizer(method='identity', center=True, transformation=None, method_kwargs={})]\n",
       "    \t), 'categorical_encoders': {'__group_id__group': NaNLabelEncoder(add_nan=False, warn=True), 'group': NaNLabelEncoder(add_nan=False, warn=True)}, 'scalers': {'time_idx': StandardScaler(), 'open': StandardScaler(), 'high': StandardScaler(), 'low': StandardScaler(), 'vopen': StandardScaler(), 'vhigh': StandardScaler(), 'vlow': StandardScaler(), 'VIX': StandardScaler(), 'SPY': StandardScaler(), 'TNX': StandardScaler(), 'rsi14': StandardScaler(), 'rsi9': StandardScaler(), 'rsi24': StandardScaler(), 'MACD5355macddiff': StandardScaler(), 'MACD5355macddiffslope': StandardScaler(), 'MACD5355macd': StandardScaler(), 'MACD5355macdslope': StandardScaler(), 'MACD5355macdsig': StandardScaler(), 'MACD5355macdsigslope': StandardScaler(), 'MACD12269macddiff': StandardScaler(), 'MACD12269macddiffslope': StandardScaler(), 'MACD12269macd': StandardScaler(), 'MACD12269macdslope': StandardScaler(), 'MACD12269macdsig': StandardScaler(), 'MACD12269macdsigslope': StandardScaler(), 'lowTail': StandardScaler(), 'highTail': StandardScaler(), 'openTail': StandardScaler(), 'IntradayBar': StandardScaler(), 'IntradayRange': StandardScaler(), 'CloseOverSMA5': StandardScaler(), 'CloseOverSMA10': StandardScaler(), 'CloseOverSMA12': StandardScaler(), 'CloseOverSMA20': StandardScaler(), 'CloseOverSMA30': StandardScaler(), 'CloseOverSMA65': StandardScaler(), 'CloseOverSMA50': StandardScaler(), 'CloseOverSMA100': StandardScaler(), 'CloseOverSMA200': StandardScaler(), 'VolOverSMA5': StandardScaler(), 'VolOverSMA10': StandardScaler(), 'VolOverSMA12': StandardScaler(), 'VolOverSMA20': StandardScaler(), 'VolOverSMA30': StandardScaler(), 'VolOverSMA65': StandardScaler(), 'VolOverSMA50': StandardScaler(), 'VolOverSMA100': StandardScaler(), 'VolOverSMA200': StandardScaler(), 'Ret1day': StandardScaler(), 'Ret4day': StandardScaler(), 'Ret8day': StandardScaler(), 'Ret12day': StandardScaler(), 'Ret24day': StandardScaler(), 'Ret72day': StandardScaler(), 'Ret240day': StandardScaler(), 'RSC': StandardScaler(), 'bands_l': StandardScaler(), 'bands_u': StandardScaler(), 'ADX': StandardScaler(), 'cloudA': StandardScaler(), 'cloudB': StandardScaler(), 'closeVsIchA': StandardScaler(), 'closeVsIchB': StandardScaler(), 'IchAvIchB': StandardScaler(), 'CondVol_1': StandardScaler(), 'CondVol_4': StandardScaler(), 'CondVol_8': StandardScaler(), 'CondVol_12': StandardScaler(), 'CondVol_24': StandardScaler(), 'CondVol_72': StandardScaler(), 'CondVol_240': StandardScaler(), 'CV1vCV4': StandardScaler(), 'CV4vCV8': StandardScaler(), 'CV8vCV12': StandardScaler(), 'CV12vCV24': StandardScaler(), 'CV8vCV24': StandardScaler(), 'CV24vCV240': StandardScaler(), 'RSC_VIX': StandardScaler(), 'RSC_VIX_IV': StandardScaler(), 'RSC_VIX_real': StandardScaler(), 'RSC_VIX_IV_real': StandardScaler(), 'RSC_IV_gar': StandardScaler(), 'close_spy_corr22': StandardScaler(), 'close_tnx_corr22': StandardScaler(), 'vclose_VIX_corr22': StandardScaler(), 'garch_IV_corr22': StandardScaler(), 'close_spy_corr65': StandardScaler(), 'close_tnx_corr65': StandardScaler(), 'vclose_VIX_corr65': StandardScaler(), 'garch_IV_corr65': StandardScaler(), 'close_spy_corr252': StandardScaler(), 'close_tnx_corr252': StandardScaler(), 'vclose_VIX_corr252': StandardScaler(), 'garch_IV_corr252': StandardScaler()}, 'randomize_length': None, 'predict_mode': False}\n",
       "    \t\"dropout\":                           0.25\n",
       "    \t\"embedding_labels\":                  {'group': {'AAPL': 0, 'ABBV': 1, 'ABT': 2, 'ACN': 3, 'ADBE': 4, 'ADI': 5, 'ADP': 6, 'ADSK': 7, 'AEP': 8, 'AFL': 9, 'AIG': 10, 'AJG': 11, 'ALL': 12, 'AMAT': 13, 'AMGN': 14, 'AMP': 15, 'AMT': 16, 'AMZN': 17, 'AON': 18, 'APD': 19, 'APH': 20, 'AXP': 21, 'AZO': 22, 'BA': 23, 'BAC': 24, 'BDX': 25, 'BK': 26, 'BKNG': 27, 'BLK': 28, 'BMY': 29, 'BRK B': 30, 'BSX': 31, 'BX': 32, 'C': 33, 'CAT': 34, 'CB': 35, 'CDNS': 36, 'CI': 37, 'CL': 38, 'CMCSA': 39, 'CME': 40, 'CMG': 41, 'CMI': 42, 'COF': 43, 'COP': 44, 'COST': 45, 'CPRT': 46, 'CRM': 47, 'CSCO': 48, 'CTAS': 49, 'CVS': 50, 'CVX': 51, 'D': 52, 'DE': 53, 'DFS': 54, 'DHR': 55, 'DIS': 56, 'DLR': 57, 'DUK': 58, 'ECL': 59, 'ELV': 60, 'EMR': 61, 'EOG': 62, 'EQIX': 63, 'ETN': 64, 'FCX': 65, 'FDX': 66, 'FI': 67, 'FTNT': 68, 'GD': 69, 'GE': 70, 'GILD': 71, 'GM': 72, 'GOOGL': 73, 'GS': 74, 'HCA': 75, 'HD': 76, 'HON': 77, 'HWM': 78, 'IBM': 79, 'ICE': 80, 'INTC': 81, 'INTU': 82, 'ISRG': 83, 'ITW': 84, 'JCI': 85, 'JNJ': 86, 'JPM': 87, 'KKR': 88, 'KLAC': 89, 'KMB': 90, 'KMI': 91, 'KO': 92, 'LLY': 93, 'LMT': 94, 'LOW': 95, 'LRCX': 96, 'MA': 97, 'MCD': 98, 'MCK': 99, 'MCO': 100, 'MDLZ': 101, 'MDT': 102, 'MET': 103, 'META': 104, 'MMC': 105, 'MMM': 106, 'MO': 107, 'MPC': 108, 'MRK': 109, 'MS': 110, 'MSFT': 111, 'MSI': 112, 'MU': 113, 'NEE': 114, 'NEM': 115, 'NFLX': 116, 'NKE': 117, 'NOC': 118, 'NOW': 119, 'NSC': 120, 'NVDA': 121, 'NXPI': 122, 'O': 123, 'OKE': 124, 'ORCL': 125, 'ORLY': 126, 'PANW': 127, 'PAYX': 128, 'PCAR': 129, 'PFE': 130, 'PG': 131, 'PGR': 132, 'PH': 133, 'PLD': 134, 'PM': 135, 'PNC': 136, 'PSA': 137, 'PSX': 138, 'QCOM': 139, 'RCL': 140, 'REGN': 141, 'ROP': 142, 'RSG': 143, 'RTX': 144, 'SBUX': 145, 'SCHW': 146, 'SHW': 147, 'SLB': 148, 'SNPS': 149, 'SO': 150, 'SPG': 151, 'SPGI': 152, 'SRE': 153, 'SYK': 154, 'T': 155, 'TDG': 156, 'TFC': 157, 'TGT': 158, 'TJX': 159, 'TMO': 160, 'TRV': 161, 'TSLA': 162, 'TT': 163, 'TXN': 164, 'UNH': 165, 'UNP': 166, 'UPS': 167, 'USB': 168, 'V': 169, 'VRTX': 170, 'VZ': 171, 'WELL': 172, 'WFC': 173, 'WM': 174, 'WMB': 175, 'WMT': 176, 'XOM': 177, 'ZTS': 178}}\n",
       "    \t\"embedding_paddings\":                []\n",
       "    \t\"embedding_sizes\":                   {'group': (179, 29)}\n",
       "    \t\"hidden_continuous_size\":            128\n",
       "    \t\"hidden_continuous_sizes\":           {}\n",
       "    \t\"hidden_size\":                       128\n",
       "    \t\"learning_rate\":                     3e-05\n",
       "    \t\"log_gradient_flow\":                 False\n",
       "    \t\"log_interval\":                      200\n",
       "    \t\"log_val_interval\":                  200\n",
       "    \t\"lstm_layers\":                       1\n",
       "    \t\"max_encoder_length\":                90\n",
       "    \t\"monotone_constaints\":               {}\n",
       "    \t\"optimizer\":                         adam\n",
       "    \t\"optimizer_params\":                  None\n",
       "    \t\"output_size\":                       [1, 1]\n",
       "    \t\"output_transformer\":                MultiNormalizer(\n",
       "    \t\tnormalizers=[TorchNormalizer(method='identity', center=True, transformation=None, method_kwargs={}), TorchNormalizer(method='identity', center=True, transformation=None, method_kwargs={})]\n",
       "    \t)\n",
       "    \t\"reduce_on_plateau_min_lr\":          1e-05\n",
       "    \t\"reduce_on_plateau_patience\":        5\n",
       "    \t\"reduce_on_plateau_reduction\":       2.0\n",
       "    \t\"share_single_variable_networks\":    False\n",
       "    \t\"static_categoricals\":               ['group']\n",
       "    \t\"static_reals\":                      []\n",
       "    \t\"time_varying_categoricals_decoder\": []\n",
       "    \t\"time_varying_categoricals_encoder\": []\n",
       "    \t\"time_varying_reals_decoder\":        ['time_idx']\n",
       "    \t\"time_varying_reals_encoder\":        ['time_idx', 'open', 'high', 'low', 'target_1', 'target_2', 'vopen', 'vhigh', 'vlow', 'VIX', 'SPY', 'TNX', 'rsi14', 'rsi9', 'rsi24', 'MACD5355macddiff', 'MACD5355macddiffslope', 'MACD5355macd', 'MACD5355macdslope', 'MACD5355macdsig', 'MACD5355macdsigslope', 'MACD12269macddiff', 'MACD12269macddiffslope', 'MACD12269macd', 'MACD12269macdslope', 'MACD12269macdsig', 'MACD12269macdsigslope', 'lowTail', 'highTail', 'openTail', 'IntradayBar', 'IntradayRange', 'CloseOverSMA5', 'CloseOverSMA10', 'CloseOverSMA12', 'CloseOverSMA20', 'CloseOverSMA30', 'CloseOverSMA65', 'CloseOverSMA50', 'CloseOverSMA100', 'CloseOverSMA200', 'VolOverSMA5', 'VolOverSMA10', 'VolOverSMA12', 'VolOverSMA20', 'VolOverSMA30', 'VolOverSMA65', 'VolOverSMA50', 'VolOverSMA100', 'VolOverSMA200', 'Ret1day', 'Ret4day', 'Ret8day', 'Ret12day', 'Ret24day', 'Ret72day', 'Ret240day', 'RSC', 'bands_l', 'bands_u', 'ADX', 'cloudA', 'cloudB', 'closeVsIchA', 'closeVsIchB', 'IchAvIchB', 'CondVol_1', 'CondVol_4', 'CondVol_8', 'CondVol_12', 'CondVol_24', 'CondVol_72', 'CondVol_240', 'CV1vCV4', 'CV4vCV8', 'CV8vCV12', 'CV12vCV24', 'CV8vCV24', 'CV24vCV240', 'RSC_VIX', 'RSC_VIX_IV', 'RSC_VIX_real', 'RSC_VIX_IV_real', 'RSC_IV_gar', 'close_spy_corr22', 'close_tnx_corr22', 'vclose_VIX_corr22', 'garch_IV_corr22', 'close_spy_corr65', 'close_tnx_corr65', 'vclose_VIX_corr65', 'garch_IV_corr65', 'close_spy_corr252', 'close_tnx_corr252', 'vclose_VIX_corr252', 'garch_IV_corr252']\n",
       "    \t\"weight_decay\":                      0.0\n",
       "    \t\"x_categoricals\":                    ['group']\n",
       "    \t\"x_reals\":                           ['time_idx', 'open', 'high', 'low', 'target_1', 'target_2', 'vopen', 'vhigh', 'vlow', 'VIX', 'SPY', 'TNX', 'rsi14', 'rsi9', 'rsi24', 'MACD5355macddiff', 'MACD5355macddiffslope', 'MACD5355macd', 'MACD5355macdslope', 'MACD5355macdsig', 'MACD5355macdsigslope', 'MACD12269macddiff', 'MACD12269macddiffslope', 'MACD12269macd', 'MACD12269macdslope', 'MACD12269macdsig', 'MACD12269macdsigslope', 'lowTail', 'highTail', 'openTail', 'IntradayBar', 'IntradayRange', 'CloseOverSMA5', 'CloseOverSMA10', 'CloseOverSMA12', 'CloseOverSMA20', 'CloseOverSMA30', 'CloseOverSMA65', 'CloseOverSMA50', 'CloseOverSMA100', 'CloseOverSMA200', 'VolOverSMA5', 'VolOverSMA10', 'VolOverSMA12', 'VolOverSMA20', 'VolOverSMA30', 'VolOverSMA65', 'VolOverSMA50', 'VolOverSMA100', 'VolOverSMA200', 'Ret1day', 'Ret4day', 'Ret8day', 'Ret12day', 'Ret24day', 'Ret72day', 'Ret240day', 'RSC', 'bands_l', 'bands_u', 'ADX', 'cloudA', 'cloudB', 'closeVsIchA', 'closeVsIchB', 'IchAvIchB', 'CondVol_1', 'CondVol_4', 'CondVol_8', 'CondVol_12', 'CondVol_24', 'CondVol_72', 'CondVol_240', 'CV1vCV4', 'CV4vCV8', 'CV8vCV12', 'CV12vCV24', 'CV8vCV24', 'CV24vCV240', 'RSC_VIX', 'RSC_VIX_IV', 'RSC_VIX_real', 'RSC_VIX_IV_real', 'RSC_IV_gar', 'close_spy_corr22', 'close_tnx_corr22', 'vclose_VIX_corr22', 'garch_IV_corr22', 'close_spy_corr65', 'close_tnx_corr65', 'vclose_VIX_corr65', 'garch_IV_corr65', 'close_spy_corr252', 'close_tnx_corr252', 'vclose_VIX_corr252', 'garch_IV_corr252']\n",
       "    (loss): MultiLoss(WrappedTorchmetric(MSELoss()), WrappedTorchmetric(MSELoss()))\n",
       "    (logging_metrics): ModuleList(\n",
       "      (0): SMAPE()\n",
       "      (1): MAE()\n",
       "      (2): RMSE()\n",
       "      (3): MAPE()\n",
       "    )\n",
       "    (input_embeddings): MultiEmbedding(\n",
       "      (embeddings): ModuleDict(\n",
       "        (group): Embedding(179, 29)\n",
       "      )\n",
       "    )\n",
       "    (prescalers): ModuleDict(\n",
       "      (time_idx): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (open): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (high): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (low): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (target_1): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (target_2): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (vopen): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (vhigh): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (vlow): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (VIX): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (SPY): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (TNX): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (rsi14): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (rsi9): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (rsi24): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (MACD5355macddiff): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (MACD5355macddiffslope): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (MACD5355macd): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (MACD5355macdslope): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (MACD5355macdsig): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (MACD5355macdsigslope): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (MACD12269macddiff): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (MACD12269macddiffslope): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (MACD12269macd): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (MACD12269macdslope): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (MACD12269macdsig): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (MACD12269macdsigslope): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (lowTail): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (highTail): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (openTail): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (IntradayBar): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (IntradayRange): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (CloseOverSMA5): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (CloseOverSMA10): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (CloseOverSMA12): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (CloseOverSMA20): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (CloseOverSMA30): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (CloseOverSMA65): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (CloseOverSMA50): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (CloseOverSMA100): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (CloseOverSMA200): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (VolOverSMA5): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (VolOverSMA10): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (VolOverSMA12): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (VolOverSMA20): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (VolOverSMA30): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (VolOverSMA65): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (VolOverSMA50): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (VolOverSMA100): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (VolOverSMA200): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (Ret1day): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (Ret4day): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (Ret8day): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (Ret12day): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (Ret24day): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (Ret72day): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (Ret240day): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (RSC): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (bands_l): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (bands_u): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (ADX): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (cloudA): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (cloudB): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (closeVsIchA): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (closeVsIchB): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (IchAvIchB): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (CondVol_1): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (CondVol_4): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (CondVol_8): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (CondVol_12): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (CondVol_24): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (CondVol_72): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (CondVol_240): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (CV1vCV4): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (CV4vCV8): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (CV8vCV12): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (CV12vCV24): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (CV8vCV24): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (CV24vCV240): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (RSC_VIX): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (RSC_VIX_IV): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (RSC_VIX_real): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (RSC_VIX_IV_real): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (RSC_IV_gar): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (close_spy_corr22): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (close_tnx_corr22): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (vclose_VIX_corr22): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (garch_IV_corr22): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (close_spy_corr65): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (close_tnx_corr65): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (vclose_VIX_corr65): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (garch_IV_corr65): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (close_spy_corr252): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (close_tnx_corr252): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (vclose_VIX_corr252): Linear(in_features=1, out_features=128, bias=True)\n",
       "      (garch_IV_corr252): Linear(in_features=1, out_features=128, bias=True)\n",
       "    )\n",
       "    (static_variable_selection): VariableSelectionNetwork(\n",
       "      (single_variable_grns): ModuleDict(\n",
       "        (group): ResampleNorm(\n",
       "          (resample): TimeDistributedInterpolation()\n",
       "          (gate): Sigmoid()\n",
       "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (prescalers): ModuleDict()\n",
       "      (softmax): Softmax(dim=-1)\n",
       "    )\n",
       "    (encoder_variable_selection): VariableSelectionNetwork(\n",
       "      (flattened_grn): GatedResidualNetwork(\n",
       "        (resample_norm): ResampleNorm(\n",
       "          (resample): TimeDistributedInterpolation()\n",
       "          (gate): Sigmoid()\n",
       "          (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (fc1): Linear(in_features=12288, out_features=96, bias=True)\n",
       "        (elu): ELU(alpha=1.0)\n",
       "        (context): Linear(in_features=128, out_features=96, bias=False)\n",
       "        (fc2): Linear(in_features=96, out_features=96, bias=True)\n",
       "        (gate_norm): GateAddNorm(\n",
       "          (glu): GatedLinearUnit(\n",
       "            (dropout): Dropout(p=0.25, inplace=False)\n",
       "            (fc): Linear(in_features=96, out_features=192, bias=True)\n",
       "          )\n",
       "          (add_norm): AddNorm(\n",
       "            (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (single_variable_grns): ModuleDict(\n",
       "        (time_idx): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (open): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (high): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (low): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (target_1): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (target_2): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (vopen): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (vhigh): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (vlow): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (VIX): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (SPY): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (TNX): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (rsi14): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (rsi9): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (rsi24): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (MACD5355macddiff): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (MACD5355macddiffslope): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (MACD5355macd): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (MACD5355macdslope): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (MACD5355macdsig): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (MACD5355macdsigslope): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (MACD12269macddiff): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (MACD12269macddiffslope): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (MACD12269macd): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (MACD12269macdslope): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (MACD12269macdsig): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (MACD12269macdsigslope): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (lowTail): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (highTail): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (openTail): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (IntradayBar): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (IntradayRange): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (CloseOverSMA5): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (CloseOverSMA10): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (CloseOverSMA12): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (CloseOverSMA20): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (CloseOverSMA30): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (CloseOverSMA65): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (CloseOverSMA50): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (CloseOverSMA100): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (CloseOverSMA200): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (VolOverSMA5): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (VolOverSMA10): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (VolOverSMA12): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (VolOverSMA20): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (VolOverSMA30): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (VolOverSMA65): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (VolOverSMA50): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (VolOverSMA100): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (VolOverSMA200): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (Ret1day): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (Ret4day): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (Ret8day): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (Ret12day): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (Ret24day): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (Ret72day): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (Ret240day): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (RSC): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (bands_l): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (bands_u): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (ADX): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (cloudA): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (cloudB): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (closeVsIchA): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (closeVsIchB): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (IchAvIchB): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (CondVol_1): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (CondVol_4): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (CondVol_8): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (CondVol_12): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (CondVol_24): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (CondVol_72): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (CondVol_240): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (CV1vCV4): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (CV4vCV8): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (CV8vCV12): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (CV12vCV24): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (CV8vCV24): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (CV24vCV240): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (RSC_VIX): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (RSC_VIX_IV): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (RSC_VIX_real): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (RSC_VIX_IV_real): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (RSC_IV_gar): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (close_spy_corr22): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (close_tnx_corr22): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (vclose_VIX_corr22): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (garch_IV_corr22): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (close_spy_corr65): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (close_tnx_corr65): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (vclose_VIX_corr65): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (garch_IV_corr65): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (close_spy_corr252): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (close_tnx_corr252): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (vclose_VIX_corr252): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (garch_IV_corr252): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (prescalers): ModuleDict(\n",
       "        (time_idx): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (open): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (high): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (low): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (target_1): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (target_2): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (vopen): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (vhigh): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (vlow): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (VIX): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (SPY): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (TNX): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (rsi14): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (rsi9): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (rsi24): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (MACD5355macddiff): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (MACD5355macddiffslope): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (MACD5355macd): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (MACD5355macdslope): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (MACD5355macdsig): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (MACD5355macdsigslope): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (MACD12269macddiff): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (MACD12269macddiffslope): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (MACD12269macd): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (MACD12269macdslope): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (MACD12269macdsig): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (MACD12269macdsigslope): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (lowTail): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (highTail): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (openTail): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (IntradayBar): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (IntradayRange): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (CloseOverSMA5): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (CloseOverSMA10): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (CloseOverSMA12): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (CloseOverSMA20): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (CloseOverSMA30): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (CloseOverSMA65): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (CloseOverSMA50): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (CloseOverSMA100): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (CloseOverSMA200): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (VolOverSMA5): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (VolOverSMA10): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (VolOverSMA12): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (VolOverSMA20): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (VolOverSMA30): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (VolOverSMA65): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (VolOverSMA50): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (VolOverSMA100): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (VolOverSMA200): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (Ret1day): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (Ret4day): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (Ret8day): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (Ret12day): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (Ret24day): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (Ret72day): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (Ret240day): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (RSC): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (bands_l): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (bands_u): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (ADX): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (cloudA): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (cloudB): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (closeVsIchA): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (closeVsIchB): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (IchAvIchB): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (CondVol_1): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (CondVol_4): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (CondVol_8): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (CondVol_12): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (CondVol_24): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (CondVol_72): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (CondVol_240): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (CV1vCV4): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (CV4vCV8): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (CV8vCV12): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (CV12vCV24): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (CV8vCV24): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (CV24vCV240): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (RSC_VIX): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (RSC_VIX_IV): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (RSC_VIX_real): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (RSC_VIX_IV_real): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (RSC_IV_gar): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (close_spy_corr22): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (close_tnx_corr22): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (vclose_VIX_corr22): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (garch_IV_corr22): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (close_spy_corr65): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (close_tnx_corr65): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (vclose_VIX_corr65): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (garch_IV_corr65): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (close_spy_corr252): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (close_tnx_corr252): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (vclose_VIX_corr252): Linear(in_features=1, out_features=128, bias=True)\n",
       "        (garch_IV_corr252): Linear(in_features=1, out_features=128, bias=True)\n",
       "      )\n",
       "      (softmax): Softmax(dim=-1)\n",
       "    )\n",
       "    (decoder_variable_selection): VariableSelectionNetwork(\n",
       "      (single_variable_grns): ModuleDict(\n",
       "        (time_idx): GatedResidualNetwork(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (elu): ELU(alpha=1.0)\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (gate_norm): GateAddNorm(\n",
       "            (glu): GatedLinearUnit(\n",
       "              (dropout): Dropout(p=0.25, inplace=False)\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (add_norm): AddNorm(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (prescalers): ModuleDict(\n",
       "        (time_idx): Linear(in_features=1, out_features=128, bias=True)\n",
       "      )\n",
       "      (softmax): Softmax(dim=-1)\n",
       "    )\n",
       "    (static_context_variable_selection): GatedResidualNetwork(\n",
       "      (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (elu): ELU(alpha=1.0)\n",
       "      (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (gate_norm): GateAddNorm(\n",
       "        (glu): GatedLinearUnit(\n",
       "          (dropout): Dropout(p=0.25, inplace=False)\n",
       "          (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "        )\n",
       "        (add_norm): AddNorm(\n",
       "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (static_context_initial_hidden_lstm): GatedResidualNetwork(\n",
       "      (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (elu): ELU(alpha=1.0)\n",
       "      (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (gate_norm): GateAddNorm(\n",
       "        (glu): GatedLinearUnit(\n",
       "          (dropout): Dropout(p=0.25, inplace=False)\n",
       "          (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "        )\n",
       "        (add_norm): AddNorm(\n",
       "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (static_context_initial_cell_lstm): GatedResidualNetwork(\n",
       "      (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (elu): ELU(alpha=1.0)\n",
       "      (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (gate_norm): GateAddNorm(\n",
       "        (glu): GatedLinearUnit(\n",
       "          (dropout): Dropout(p=0.25, inplace=False)\n",
       "          (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "        )\n",
       "        (add_norm): AddNorm(\n",
       "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (static_context_enrichment): GatedResidualNetwork(\n",
       "      (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (elu): ELU(alpha=1.0)\n",
       "      (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (gate_norm): GateAddNorm(\n",
       "        (glu): GatedLinearUnit(\n",
       "          (dropout): Dropout(p=0.25, inplace=False)\n",
       "          (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "        )\n",
       "        (add_norm): AddNorm(\n",
       "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (lstm_encoder): LSTM(128, 128, batch_first=True)\n",
       "    (lstm_decoder): LSTM(128, 128, batch_first=True)\n",
       "    (post_lstm_gate_encoder): GatedLinearUnit(\n",
       "      (dropout): Dropout(p=0.25, inplace=False)\n",
       "      (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "    )\n",
       "    (post_lstm_gate_decoder): GatedLinearUnit(\n",
       "      (dropout): Dropout(p=0.25, inplace=False)\n",
       "      (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "    )\n",
       "    (post_lstm_add_norm_encoder): AddNorm(\n",
       "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (post_lstm_add_norm_decoder): AddNorm(\n",
       "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (static_enrichment): GatedResidualNetwork(\n",
       "      (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (elu): ELU(alpha=1.0)\n",
       "      (context): Linear(in_features=128, out_features=128, bias=False)\n",
       "      (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (gate_norm): GateAddNorm(\n",
       "        (glu): GatedLinearUnit(\n",
       "          (dropout): Dropout(p=0.25, inplace=False)\n",
       "          (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "        )\n",
       "        (add_norm): AddNorm(\n",
       "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (multihead_attn): InterpretableMultiHeadAttention(\n",
       "      (dropout): Dropout(p=0.25, inplace=False)\n",
       "      (v_layer): Linear(in_features=128, out_features=32, bias=True)\n",
       "      (q_layers): ModuleList(\n",
       "        (0-3): 4 x Linear(in_features=128, out_features=32, bias=True)\n",
       "      )\n",
       "      (k_layers): ModuleList(\n",
       "        (0-3): 4 x Linear(in_features=128, out_features=32, bias=True)\n",
       "      )\n",
       "      (attention): ScaledDotProductAttention(\n",
       "        (softmax): Softmax(dim=2)\n",
       "      )\n",
       "      (w_h): Linear(in_features=32, out_features=128, bias=False)\n",
       "    )\n",
       "    (post_attn_gate_norm): GateAddNorm(\n",
       "      (glu): GatedLinearUnit(\n",
       "        (dropout): Dropout(p=0.25, inplace=False)\n",
       "        (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "      )\n",
       "      (add_norm): AddNorm(\n",
       "        (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (pos_wise_ff): GatedResidualNetwork(\n",
       "      (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (elu): ELU(alpha=1.0)\n",
       "      (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (gate_norm): GateAddNorm(\n",
       "        (glu): GatedLinearUnit(\n",
       "          (dropout): Dropout(p=0.25, inplace=False)\n",
       "          (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "        )\n",
       "        (add_norm): AddNorm(\n",
       "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pre_output_gate_norm): GateAddNorm(\n",
       "      (glu): GatedLinearUnit(\n",
       "        (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "      )\n",
       "      (add_norm): AddNorm(\n",
       "        (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (output_layer): ModuleList(\n",
       "      (0-1): 2 x Linear(in_features=128, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.errors import EmptyDataError\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_forecasting.data import TimeSeriesDataSet\n",
    "from pytorch_forecasting.models import TemporalFusionTransformer\n",
    "from pytorch_forecasting.metrics import MultiLoss\n",
    "from pytorch_forecasting.data.encoders import MultiNormalizer, TorchNormalizer\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "### Model Path\n",
    "modelPath=\"./models/mar22_model.pth\"\n",
    "\n",
    "###\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.set_float32_matmul_precision(\"medium\")  # For NVIDIA Tensor Cores\n",
    "print(\"Using device:\", DEVICE)\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Data Loading\n",
    "# -----------------------------\n",
    "def load_data(folder):\n",
    "    all_files = [os.path.join(folder, f) for f in os.listdir(folder) if f.endswith('.csv')]\n",
    "    dfs = []\n",
    "    for file in all_files:\n",
    "        try:\n",
    "            df = pd.read_csv(file)\n",
    "            if df.empty:\n",
    "                print(f\"Warning: File {file} is empty; skipping.\")\n",
    "                continue\n",
    "            df = df.reset_index(drop=True)\n",
    "            # Only drop the 'date' column if it exists\n",
    "            if 'date' in df.columns:\n",
    "                df = df.drop('date', axis=1)\n",
    "            else:\n",
    "                print(f\"Warning: File {file} does not contain a 'date' column.\")\n",
    "            df[\"time_idx\"] = range(len(df))\n",
    "            df[\"group\"] = os.path.basename(file).split('.')[0]\n",
    "            df[\"group\"] = df[\"group\"].astype(str)\n",
    "            df.rename(columns={\"Close\": \"target_1\", \"vclose\": \"target_2\"}, inplace=True)\n",
    "            dfs.append(df)\n",
    "        except EmptyDataError:\n",
    "            print(f\"EmptyDataError: File {file} is empty or has no columns; skipping.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {file}: {e}\")\n",
    "    if dfs:\n",
    "        return pd.concat(dfs, ignore_index=True)\n",
    "    else:\n",
    "        print(f\"No data loaded from folder: {folder}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "train_data_folder = \"data/train\"\n",
    "test_data_folder  = \"data/test\"\n",
    "oos_data_folder   = \"data/oos\"\n",
    "\n",
    "train_df = load_data(train_data_folder)\n",
    "test_df  = load_data(test_data_folder)\n",
    "oos_df   = load_data(oos_data_folder)\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Multi-Target Dataset\n",
    "# -----------------------------\n",
    "training = TimeSeriesDataSet(\n",
    "    train_df,\n",
    "    time_idx=\"time_idx\",\n",
    "    target=[\"target_1\", \"target_2\"],\n",
    "    group_ids=[\"group\"],\n",
    "    max_encoder_length=90,\n",
    "    max_prediction_length=5,\n",
    "    static_categoricals=[\"group\"],\n",
    "    time_varying_known_reals=[\"time_idx\"],\n",
    "    time_varying_unknown_reals=[\n",
    "        c for c in train_df.columns if c not in [\"group\", \"time_idx\"]#, \"target_1\", \"target_2\"]\n",
    "    ],\n",
    "    target_normalizer=MultiNormalizer([\n",
    "        TorchNormalizer(method=\"identity\"),\n",
    "        TorchNormalizer(method=\"identity\")\n",
    "    ])\n",
    ")\n",
    "\n",
    "# validation & OOS sets with predict_mode=False -> keep target data\n",
    "validation = TimeSeriesDataSet.from_dataset(training, test_df, predict_mode=False)\n",
    "oos        = TimeSeriesDataSet.from_dataset(training, oos_df,  predict_mode=False)\n",
    "\n",
    "# -----------------------------\n",
    "# 4. DataLoaders\n",
    "# -----------------------------\n",
    "train_dataloader = training.to_dataloader(\n",
    "    train=True, batch_size=64, shuffle=True, num_workers=4, pin_memory=False\n",
    ")\n",
    "val_dataloader = validation.to_dataloader(\n",
    "    train=False, batch_size=32, shuffle=False, num_workers=4, pin_memory=False\n",
    ")\n",
    "oos_dataloader = oos.to_dataloader(\n",
    "    train=False, batch_size=16, shuffle=False, num_workers=4, pin_memory=False\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Define Multi-Target TFT Model w/ Quantile Loss\n",
    "# -----------------------------\n",
    "import torch.nn as nn\n",
    "\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    training,\n",
    "    learning_rate=3e-05,\n",
    "    lstm_layers=1,\n",
    "    hidden_size=128,\n",
    "    attention_head_size=4,\n",
    "    dropout=0.25,\n",
    "    hidden_continuous_size=128,\n",
    "    output_size=[1, 1],  # single output per target for MSE\n",
    "    loss=MultiLoss([\n",
    "        nn.MSELoss(),\n",
    "        nn.MSELoss()\n",
    "    ]),\n",
    "    log_interval=200,\n",
    "    reduce_on_plateau_patience=5,\n",
    ").to(DEVICE)\n",
    "\n",
    "print(f\"Number of params in network: {tft.size() / 1e3:.1f}k\")\n",
    "\n",
    "# -----------------------------\n",
    "# 6. LightningModule\n",
    "# -----------------------------\n",
    "class TFTLightningModule(LightningModule):\n",
    "    def __init__(self, tft_model):\n",
    "        super().__init__()\n",
    "        self.tft_model = tft_model\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.tft_model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        # 'y' is a tuple: ([target0_tensor, target1_tensor], None)\n",
    "        out = self(x)\n",
    "        pred = out[\"prediction\"]  # list: 0 => target0, 1 => target1\n",
    "        loss = self.tft_model.loss(pred, y)  # automatically handles multi-target\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        out = self(x)\n",
    "        pred = out[\"prediction\"]\n",
    "        loss = self.tft_model.loss(pred, y)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return self.tft_model.configure_optimizers()\n",
    "\n",
    "    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n",
    "        # If the batch is a (x, y) tuple, we only pass x to the model\n",
    "        if isinstance(batch, (tuple, list)):\n",
    "            x = batch[0]\n",
    "        else:\n",
    "            x = batch\n",
    "        return self(x)\n",
    "\n",
    "tft_module = TFTLightningModule(tft).to(DEVICE)\n",
    "\n",
    "# Optional: training setup\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", patience=7, mode=\"min\")\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=\"checkpoints/\",\n",
    "    filename=\"my-tft-{epoch:02d}-{val_loss:.2f}\",\n",
    "    save_top_k=1,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=35,   # set higher for real training\n",
    "    accelerator=\"gpu\" if DEVICE == \"cuda\" else \"cpu\",\n",
    "    devices=1,\n",
    "    precision=32,\n",
    "    logger=CSVLogger(\"logs\", name=\"tft_multi_target_quantile\"),\n",
    "    callbacks=[early_stop_callback, checkpoint_callback],\n",
    ")\n",
    "\n",
    "# --- Load the saved state dict ---\n",
    "state_dict = torch.load(modelPath, map_location=DEVICE)\n",
    "tft_module.load_state_dict(state_dict)\n",
    "tft_module.to(DEVICE)\n",
    "tft_module.eval()  # set the model to evaluation mode\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict w/ loaded model. RSM ranking from validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing CSCO ...\n",
      "Processing ISRG ...\n",
      "Processing BA ...\n",
      "Processing VRTX ...\n",
      "Processing GILD ...\n",
      "Processing EQIX ...\n",
      "Processing MDT ...\n",
      "Processing V ...\n",
      "Processing MO ...\n",
      "Processing CDNS ...\n",
      "Processing HCA ...\n",
      "Processing AJG ...\n",
      "Processing C ...\n",
      "Processing T ...\n",
      "Processing APH ...\n",
      "Processing MSI ...\n",
      "Processing FCX ...\n",
      "Processing BAC ...\n",
      "Processing PSX ...\n",
      "Processing ADI ...\n",
      "Processing ADBE ...\n",
      "Processing CPRT ...\n",
      "Processing TDG ...\n",
      "Processing SYK ...\n",
      "Processing CB ...\n",
      "Processing NOW ...\n",
      "Processing LLY ...\n",
      "Processing COST ...\n",
      "Processing LOW ...\n",
      "Processing MDLZ ...\n",
      "Processing BKNG ...\n",
      "Processing MET ...\n",
      "Processing DLR ...\n",
      "Processing TJX ...\n",
      "Processing MPC ...\n",
      "Processing D ...\n",
      "Processing MRK ...\n",
      "Processing NOC ...\n",
      "Processing UNP ...\n",
      "Processing ABBV ...\n",
      "Processing ORCL ...\n",
      "Processing ECL ...\n",
      "Processing SBUX ...\n",
      "Processing AMT ...\n",
      "Processing INTU ...\n",
      "Processing PG ...\n",
      "Processing CAT ...\n",
      "Processing MCD ...\n",
      "Processing AMZN ...\n",
      "Processing INTC ...\n",
      "Processing BDX ...\n",
      "Processing KMI ...\n",
      "Processing WELL ...\n",
      "Processing GM ...\n",
      "Processing TXN ...\n",
      "Processing FI ...\n",
      "Processing TMO ...\n",
      "Processing MMM ...\n",
      "Processing FTNT ...\n",
      "Error retrieving mu/sig for FTNT: index 0 is out of bounds for axis 0 with size 0\n",
      "Processing ADSK ...\n",
      "Processing KO ...\n",
      "Processing PCAR ...\n",
      "Processing NEE ...\n",
      "Processing UPS ...\n",
      "Processing ELV ...\n",
      "Processing EMR ...\n",
      "Processing MSFT ...\n",
      "Processing CTAS ...\n",
      "Processing ACN ...\n",
      "Processing CMG ...\n",
      "Processing SHW ...\n",
      "Processing AMAT ...\n",
      "Processing DE ...\n",
      "Processing SPG ...\n",
      "Processing KLAC ...\n",
      "Processing RTX ...\n",
      "Processing NXPI ...\n",
      "Processing PNC ...\n",
      "Processing NVDA ...\n",
      "Processing ROP ...\n",
      "Processing HD ...\n",
      "Processing AON ...\n",
      "Processing ZTS ...\n",
      "Processing FDX ...\n",
      "Processing SCHW ...\n",
      "Processing AZO ...\n",
      "Processing AXP ...\n",
      "Processing DFS ...\n",
      "Processing SO ...\n",
      "Processing CME ...\n",
      "Processing XOM ...\n",
      "Processing AMP ...\n",
      "Processing CVX ...\n",
      "Processing CMCSA ...\n",
      "Processing ICE ...\n",
      "Processing NSC ...\n",
      "Processing NKE ...\n",
      "Processing CMI ...\n",
      "Processing PLD ...\n",
      "Processing IBM ...\n",
      "Processing USB ...\n",
      "Processing BSX ...\n",
      "Processing ITW ...\n",
      "Processing EOG ...\n",
      "Processing KMB ...\n",
      "Processing SPGI ...\n",
      "Processing NEM ...\n",
      "Processing WFC ...\n",
      "Processing GS ...\n",
      "Processing GD ...\n",
      "Processing PM ...\n",
      "Processing MCO ...\n",
      "Processing PANW ...\n",
      "Processing DIS ...\n",
      "Processing GE ...\n",
      "Processing ALL ...\n",
      "Processing ETN ...\n",
      "Processing NFLX ...\n",
      "Processing CVS ...\n",
      "Processing JPM ...\n",
      "Processing ABT ...\n",
      "Processing COF ...\n",
      "Processing PH ...\n",
      "Processing TSLA ...\n",
      "Processing COP ...\n",
      "Processing DHR ...\n",
      "Processing MCK ...\n",
      "Processing GOOGL ...\n",
      "Processing PAYX ...\n",
      "Processing META ...\n",
      "Processing MMC ...\n",
      "Processing SRE ...\n",
      "Processing ORLY ...\n",
      "Processing RCL ...\n",
      "Processing SNPS ...\n",
      "Processing PFE ...\n",
      "Processing DUK ...\n",
      "Processing REGN ...\n",
      "Processing CL ...\n",
      "Processing VZ ...\n",
      "Processing JCI ...\n",
      "Processing AMGN ...\n",
      "Processing ADP ...\n",
      "Processing RSG ...\n",
      "Processing QCOM ...\n",
      "Processing MS ...\n",
      "Processing OKE ...\n",
      "Processing BK ...\n",
      "Processing HWM ...\n",
      "Processing TFC ...\n",
      "Processing AFL ...\n",
      "Processing BRK B ...\n",
      "Processing UNH ...\n",
      "Processing WMB ...\n",
      "Processing AIG ...\n",
      "Processing MA ...\n",
      "Processing HON ...\n",
      "Processing O ...\n",
      "Processing SLB ...\n",
      "Processing TT ...\n",
      "Processing TGT ...\n",
      "Processing AAPL ...\n",
      "Processing APD ...\n",
      "Processing BX ...\n",
      "Processing WMT ...\n",
      "Processing LMT ...\n",
      "Processing KKR ...\n",
      "Processing BMY ...\n",
      "Processing PSA ...\n",
      "Processing MU ...\n",
      "Processing TRV ...\n",
      "Processing AEP ...\n",
      "Processing CI ...\n",
      "Processing JNJ ...\n",
      "Processing WM ...\n",
      "Processing CRM ...\n",
      "Processing PGR ...\n",
      "Processing LRCX ...\n",
      "Processing BLK ...\n",
      "\n",
      "Results DataFrame:\n",
      "    Symbol       MSE     Pred1     Pred2     Pred3     Pred4     Pred5  \\\n",
      "0     CSCO  0.380242  1.241838  1.246531  1.246660  1.244370  1.240903   \n",
      "1     ISRG  0.257771  0.665185  0.654707  0.657980  0.664860  0.672214   \n",
      "2       BA  1.181174  0.494835  0.514800  0.526213  0.533033  0.537094   \n",
      "3     VRTX  0.006159  1.559604  1.585476  1.585641  1.570333  1.544943   \n",
      "4     GILD  1.675728  1.638515  1.681123  1.689428  1.678308  1.654406   \n",
      "..     ...       ...       ...       ...       ...       ...       ...   \n",
      "173     WM  0.016232  1.683577  1.726077  1.735552  1.726380  1.705001   \n",
      "174    CRM  0.405794 -0.022672 -0.065541 -0.061904 -0.038613 -0.004998   \n",
      "175    PGR  0.311716  1.628494  1.667211  1.672741  1.660459  1.637087   \n",
      "176   LRCX  0.868279 -0.962325 -1.024107 -1.023386 -0.998678 -0.962986   \n",
      "177    BLK  0.178589  0.597208  0.594388  0.602181  0.614001  0.626998   \n",
      "\n",
      "        Delta  \n",
      "0   -0.000935  \n",
      "1    0.007029  \n",
      "2    0.042259  \n",
      "3   -0.014661  \n",
      "4    0.015891  \n",
      "..        ...  \n",
      "173  0.021424  \n",
      "174  0.017674  \n",
      "175  0.008593  \n",
      "176 -0.000661  \n",
      "177  0.029789  \n",
      "\n",
      "[178 rows x 8 columns]\n",
      "\n",
      "Ranked by MSE:\n",
      "    Symbol       MSE     Pred1     Pred2     Pred3     Pred4     Pred5  \\\n",
      "3     VRTX  0.006159  1.559604  1.585476  1.585641  1.570333  1.544943   \n",
      "76     PNC  0.010367  0.023009  0.004248  0.017883  0.042920  0.072404   \n",
      "155    HON  0.011706  0.449890  0.421840  0.417410  0.422838  0.432534   \n",
      "82     FDX  0.012560 -1.996725 -2.028531 -1.989355 -1.929581 -1.861206   \n",
      "148    TFC  0.013005  0.201100  0.186558  0.196520  0.214745  0.235854   \n",
      "..     ...       ...       ...       ...       ...       ...       ...   \n",
      "47     MCD  2.250653  1.335243  1.345187  1.343812  1.336459  1.325444   \n",
      "80     AON  2.527645  1.411912  1.424782  1.422294  1.411557  1.395887   \n",
      "42    SBUX  2.607237  0.493908  0.457415  0.448103  0.451020  0.460492   \n",
      "29    MDLZ  3.264079 -0.661998 -0.685529 -0.670371 -0.639603 -0.602536   \n",
      "88     CME  3.565239  2.415075  2.474594  2.481269  2.461868  2.426861   \n",
      "\n",
      "        Delta  \n",
      "3   -0.014661  \n",
      "76   0.049395  \n",
      "155 -0.017355  \n",
      "82   0.135518  \n",
      "148  0.034754  \n",
      "..        ...  \n",
      "47  -0.009799  \n",
      "80  -0.016024  \n",
      "42  -0.033416  \n",
      "29   0.059462  \n",
      "88   0.011786  \n",
      "\n",
      "[178 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "saveAs = './predictions/RankedPreds_3-22_Model.csv'\n",
    "\n",
    "mu_sig_df = pd.read_csv('./data/TixMuSig.csv')\n",
    "\n",
    "def move_to_device(batch_x, device):\n",
    "    \"\"\"Ensure all Tensors in batch_x are on the same device.\"\"\"\n",
    "    if isinstance(batch_x, torch.Tensor):\n",
    "        return batch_x.to(device)\n",
    "    elif isinstance(batch_x, dict):\n",
    "        return {k: move_to_device(v, device) for k, v in batch_x.items()}\n",
    "    elif isinstance(batch_x, list):\n",
    "        return [move_to_device(item, device) for item in batch_x]\n",
    "    else:\n",
    "        return batch_x\n",
    "\n",
    "def process_symbol(symbol):\n",
    "    # Filter the full oos dataframe for this symbol (group)\n",
    "    stock_oos_df = oos_df[oos_df[\"group\"] == symbol]\n",
    "    if stock_oos_df.empty:\n",
    "        print(f\"No OOS data for {symbol}.\")\n",
    "        return None\n",
    "\n",
    "    # Retrieve the scaling parameters for price (target_1) from mu_sig_df.\n",
    "    try:\n",
    "        mu_p = mu_sig_df.loc[mu_sig_df['ticker'] == symbol, 'closemu'].values[0]\n",
    "        sig_p = mu_sig_df.loc[mu_sig_df['ticker'] == symbol, 'closesig'].values[0]\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving mu/sig for {symbol}: {e}\")\n",
    "        return None\n",
    "\n",
    "    # -------------------------------------------------------------------\n",
    "    # Create two datasets:\n",
    "    # 1. For current predictions (no future targets provided)\n",
    "    eq_dataset_current = TimeSeriesDataSet.from_dataset(\n",
    "        training, stock_oos_df, predict_mode=True\n",
    "    )\n",
    "    eq_dataloader_current = eq_dataset_current.to_dataloader(\n",
    "        train=False,\n",
    "        batch_size=len(eq_dataset_current),  # All samples in one batch\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        pin_memory=False\n",
    "    )\n",
    "\n",
    "    # 2. For backtesting (to compute MSE, future values are provided)\n",
    "    eq_dataset_backtest = TimeSeriesDataSet.from_dataset(\n",
    "        training, stock_oos_df, predict_mode=False\n",
    "    )\n",
    "    eq_dataloader_backtest = eq_dataset_backtest.to_dataloader(\n",
    "        train=False,\n",
    "        batch_size=len(eq_dataset_backtest),  # All samples in one batch\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        pin_memory=False\n",
    "    )\n",
    "    # -------------------------------------------------------------------\n",
    "\n",
    "    # --- Get current predictions (using predict_mode=True) ---\n",
    "    with torch.no_grad():\n",
    "        for batch in eq_dataloader_current:\n",
    "            x_current, _ = batch  # y is not used in predict_mode=True\n",
    "            x_current = move_to_device(x_current, DEVICE)\n",
    "            out_current = tft_module(x_current)\n",
    "            preds_current = out_current[\"prediction\"]\n",
    "            # Assuming target_1 is at index 0 and we use the median (index 0 when using MSE)\n",
    "            current_price_preds = preds_current[0][:, :, 0].cpu()  # shape: (batch, prediction_length)\n",
    "\n",
    "    # Extract Pred1Pred5 from current predictions:\n",
    "    # (Assuming prediction_length is 5 and batch size is 1)\n",
    "    pred1 = current_price_preds[0, 0].item()\n",
    "    pred2 = current_price_preds[0, 1].item()\n",
    "    pred3 = current_price_preds[0, 2].item()\n",
    "    pred4 = current_price_preds[0, 3].item()\n",
    "    pred5 = current_price_preds[0, 4].item()\n",
    "    # print(current_price_preds[0])\n",
    "\n",
    "\n",
    "    # --- Get backtest predictions for MSE calculation (using predict_mode=False) ---\n",
    "    with torch.no_grad():\n",
    "        for batch in eq_dataloader_backtest:\n",
    "            x_backtest, y_tuple = batch\n",
    "            y_list, _ = y_tuple\n",
    "            # Get the actual future values for target_1.\n",
    "            actual_future = y_list[0]  # shape: [batch, prediction_length]\n",
    "            x_backtest = move_to_device(x_backtest, DEVICE)\n",
    "            out_backtest = tft_module(x_backtest)\n",
    "            preds_backtest = out_backtest[\"prediction\"]\n",
    "            backtest_price_preds = preds_backtest[0][:, :, 0].cpu()\n",
    "\n",
    "    # Compute MSE over the forecast horizon using the backtest data.\n",
    "    mse_value = torch.mean((backtest_price_preds[0] - actual_future[0])**2).item()\n",
    "    # plt.plot(backtest_price_preds)\n",
    "    # plt.plot(actual_future)\n",
    "    # plt.show()\n",
    "    # Build the result dictionary.\n",
    "    result = {\n",
    "        \"Symbol\": symbol,\n",
    "        \"MSE\": mse_value,\n",
    "        \"Pred1\": pred1,\n",
    "        \"Pred2\": pred2,\n",
    "        \"Pred3\": pred3,\n",
    "        \"Pred4\": pred4,\n",
    "        \"Pred5\": pred5,\n",
    "        \"Delta\": pred5-pred1,\n",
    "    }\n",
    "    return result\n",
    "\n",
    "# Loop over each CSV file in \"./data/oos\" and collect results.\n",
    "results_list = []\n",
    "oos_folder = \"./data/oos\"\n",
    "oos_files = [f for f in os.listdir(oos_folder) if f.endswith('.csv')]\n",
    "for file in oos_files:#[:6]:\n",
    "    symbol = os.path.splitext(file)[0].upper()\n",
    "    print(f\"Processing {symbol} ...\")\n",
    "    res = process_symbol(symbol)\n",
    "    if res is not None:\n",
    "        results_list.append(res)\n",
    "\n",
    "results_df = pd.DataFrame(results_list)\n",
    "print(\"\\nResults DataFrame:\")\n",
    "print(results_df)\n",
    "\n",
    "results_df_sorted = results_df.sort_values(by=\"MSE\")\n",
    "print(\"\\nRanked by MSE:\")\n",
    "print(results_df_sorted)\n",
    "results_df_sorted.to_csv(saveAs, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule Based Trades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>MSE</th>\n",
       "      <th>Pred1</th>\n",
       "      <th>Pred2</th>\n",
       "      <th>Pred3</th>\n",
       "      <th>Pred4</th>\n",
       "      <th>Pred5</th>\n",
       "      <th>Delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VRTX</td>\n",
       "      <td>0.006159</td>\n",
       "      <td>1.559604</td>\n",
       "      <td>1.585476</td>\n",
       "      <td>1.585641</td>\n",
       "      <td>1.570333</td>\n",
       "      <td>1.544943</td>\n",
       "      <td>-0.014661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PNC</td>\n",
       "      <td>0.010367</td>\n",
       "      <td>0.023009</td>\n",
       "      <td>0.004248</td>\n",
       "      <td>0.017883</td>\n",
       "      <td>0.042920</td>\n",
       "      <td>0.072404</td>\n",
       "      <td>0.049395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HON</td>\n",
       "      <td>0.011706</td>\n",
       "      <td>0.449890</td>\n",
       "      <td>0.421840</td>\n",
       "      <td>0.417410</td>\n",
       "      <td>0.422838</td>\n",
       "      <td>0.432534</td>\n",
       "      <td>-0.017355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FDX</td>\n",
       "      <td>0.012560</td>\n",
       "      <td>-1.996725</td>\n",
       "      <td>-2.028531</td>\n",
       "      <td>-1.989355</td>\n",
       "      <td>-1.929581</td>\n",
       "      <td>-1.861206</td>\n",
       "      <td>0.135518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TFC</td>\n",
       "      <td>0.013005</td>\n",
       "      <td>0.201100</td>\n",
       "      <td>0.186558</td>\n",
       "      <td>0.196520</td>\n",
       "      <td>0.214745</td>\n",
       "      <td>0.235854</td>\n",
       "      <td>0.034754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>MCD</td>\n",
       "      <td>2.250653</td>\n",
       "      <td>1.335243</td>\n",
       "      <td>1.345187</td>\n",
       "      <td>1.343812</td>\n",
       "      <td>1.336459</td>\n",
       "      <td>1.325444</td>\n",
       "      <td>-0.009799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>AON</td>\n",
       "      <td>2.527645</td>\n",
       "      <td>1.411912</td>\n",
       "      <td>1.424782</td>\n",
       "      <td>1.422294</td>\n",
       "      <td>1.411557</td>\n",
       "      <td>1.395887</td>\n",
       "      <td>-0.016024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>SBUX</td>\n",
       "      <td>2.607237</td>\n",
       "      <td>0.493908</td>\n",
       "      <td>0.457415</td>\n",
       "      <td>0.448103</td>\n",
       "      <td>0.451020</td>\n",
       "      <td>0.460492</td>\n",
       "      <td>-0.033416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>MDLZ</td>\n",
       "      <td>3.264079</td>\n",
       "      <td>-0.661998</td>\n",
       "      <td>-0.685529</td>\n",
       "      <td>-0.670371</td>\n",
       "      <td>-0.639603</td>\n",
       "      <td>-0.602536</td>\n",
       "      <td>0.059462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>CME</td>\n",
       "      <td>3.565239</td>\n",
       "      <td>2.415075</td>\n",
       "      <td>2.474594</td>\n",
       "      <td>2.481269</td>\n",
       "      <td>2.461868</td>\n",
       "      <td>2.426861</td>\n",
       "      <td>0.011786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows  8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Symbol       MSE     Pred1     Pred2     Pred3     Pred4     Pred5  \\\n",
       "0     VRTX  0.006159  1.559604  1.585476  1.585641  1.570333  1.544943   \n",
       "1      PNC  0.010367  0.023009  0.004248  0.017883  0.042920  0.072404   \n",
       "2      HON  0.011706  0.449890  0.421840  0.417410  0.422838  0.432534   \n",
       "3      FDX  0.012560 -1.996725 -2.028531 -1.989355 -1.929581 -1.861206   \n",
       "4      TFC  0.013005  0.201100  0.186558  0.196520  0.214745  0.235854   \n",
       "..     ...       ...       ...       ...       ...       ...       ...   \n",
       "173    MCD  2.250653  1.335243  1.345187  1.343812  1.336459  1.325444   \n",
       "174    AON  2.527645  1.411912  1.424782  1.422294  1.411557  1.395887   \n",
       "175   SBUX  2.607237  0.493908  0.457415  0.448103  0.451020  0.460492   \n",
       "176   MDLZ  3.264079 -0.661998 -0.685529 -0.670371 -0.639603 -0.602536   \n",
       "177    CME  3.565239  2.415075  2.474594  2.481269  2.461868  2.426861   \n",
       "\n",
       "        Delta  \n",
       "0   -0.014661  \n",
       "1    0.049395  \n",
       "2   -0.017355  \n",
       "3    0.135518  \n",
       "4    0.034754  \n",
       "..        ...  \n",
       "173 -0.009799  \n",
       "174 -0.016024  \n",
       "175 -0.033416  \n",
       "176  0.059462  \n",
       "177  0.011786  \n",
       "\n",
       "[178 rows x 8 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>MSE</th>\n",
       "      <th>Pred1</th>\n",
       "      <th>Pred2</th>\n",
       "      <th>Pred3</th>\n",
       "      <th>Pred4</th>\n",
       "      <th>Pred5</th>\n",
       "      <th>Delta</th>\n",
       "      <th>Bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FDX</td>\n",
       "      <td>0.01256</td>\n",
       "      <td>-1.996725</td>\n",
       "      <td>-2.028531</td>\n",
       "      <td>-1.989355</td>\n",
       "      <td>-1.929581</td>\n",
       "      <td>-1.861206</td>\n",
       "      <td>0.135518</td>\n",
       "      <td>Long</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Symbol      MSE     Pred1     Pred2     Pred3     Pred4     Pred5     Delta  \\\n",
       "3    FDX  0.01256 -1.996725 -2.028531 -1.989355 -1.929581 -1.861206  0.135518   \n",
       "\n",
       "   Bias  \n",
       "3  Long  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_sorted = pd.read_csv('/Users/alecjeffery/Documents/Playgrounds/Python/TFT/predictions/RankedPreds_3-22_Model.csv')\n",
    "ProposedTrades = results_df_sorted[(results_df_sorted['MSE'] < 0.1) & \n",
    "                  ((results_df_sorted['Delta'] > 0.1) | (results_df_sorted['Delta'] < -0.1))\n",
    "                  ].sort_values(by=\"Delta\", ascending=False)\n",
    "ProposedTrades.loc[ProposedTrades['Delta'] > 0, 'Bias'] = 'Long'\n",
    "ProposedTrades.loc[ProposedTrades['Delta'] < 0, 'Bias'] = 'Short'\n",
    "ProposedTrades"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spacetimeformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
